{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data/FashionMNIST\n",
       "    Split: Train"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(root='./data/FashionMNIST', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = torchvision.datasets.FashionMNIST(root='./data/FashionMNIST', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1)\n",
    "\n",
    "data_loader = {\n",
    "    'train': train_loader,\n",
    "    'val': test_loader\n",
    "}\n",
    "\n",
    "data_size = {\n",
    "    'train': len(train_set),\n",
    "    'val': len(test_set)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 =nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = F.max_pool2d(F.relu(self.conv1(t)), kernel_size=2)\n",
    "        t = F.max_pool2d(F.relu(self.conv2(t)), kernel_size=2)\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1) # Loss function we are going to use performs the softmax function\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "lr = 0.01\n",
    "epochs = 10\n",
    "optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "best_acc = 0.0\n",
    "best_model_weights = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter(comment=\"test_network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 train loss: 3909.393696174724 Number correct: 45180 Accuracy: 75.3 %\n",
      "Epoch: 0 val loss: 5424.159754067659 Number correct: 8050 Accuracy: 80.5 %\n",
      "Epoch: 1 train loss: 3200.9323345459998 Number correct: 48580 Accuracy: 80.96666666666667 %\n",
      "Epoch: 1 val loss: 5160.5871496498585 Number correct: 8198 Accuracy: 81.98 %\n",
      "Epoch: 2 train loss: 3149.088037339039 Number correct: 48935 Accuracy: 81.55833333333334 %\n",
      "Epoch: 2 val loss: 5289.056150257587 Number correct: 8083 Accuracy: 80.83 %\n",
      "Epoch: 3 train loss: 3121.4850941256154 Number correct: 49011 Accuracy: 81.685 %\n",
      "Epoch: 3 val loss: 5959.346417343244 Number correct: 8063 Accuracy: 80.63 %\n",
      "Epoch: 4 train loss: 3116.6658673509955 Number correct: 48914 Accuracy: 81.52333333333334 %\n",
      "Epoch: 4 val loss: 5410.351660350338 Number correct: 8241 Accuracy: 82.41000000000001 %\n",
      "Epoch: 5 train loss: 3101.6673413878307 Number correct: 49197 Accuracy: 81.99499999999999 %\n",
      "Epoch: 5 val loss: 5204.646502256393 Number correct: 8227 Accuracy: 82.27 %\n",
      "Epoch: 6 train loss: 3063.32638643845 Number correct: 49215 Accuracy: 82.025 %\n",
      "Epoch: 6 val loss: 5377.632599350065 Number correct: 8185 Accuracy: 81.85 %\n",
      "Epoch: 7 train loss: 3042.073300478747 Number correct: 49309 Accuracy: 82.18166666666666 %\n",
      "Epoch: 7 val loss: 6996.112833373249 Number correct: 7662 Accuracy: 76.62 %\n",
      "Epoch: 8 train loss: 3035.99551836052 Number correct: 49411 Accuracy: 82.35166666666667 %\n",
      "Epoch: 8 val loss: 4983.135376639664 Number correct: 8255 Accuracy: 82.55 %\n",
      "Epoch: 9 train loss: 2995.155732645886 Number correct: 49549 Accuracy: 82.58166666666666 %\n",
      "Epoch: 9 val loss: 5457.112121349201 Number correct: 8196 Accuracy: 81.96 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            network.train()\n",
    "        else:\n",
    "            network.eval()\n",
    "        \n",
    "        running_loss = 0\n",
    "        num_correct = 0\n",
    "        \n",
    "        for batch in data_loader[phase]:\n",
    "            images, labels = batch\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                predictions = network(images)\n",
    "                loss = F.cross_entropy(predictions, labels)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "            running_loss += loss.item()\n",
    "            num_correct += predictions.argmax(dim=1).eq(labels).sum().item()\n",
    "        \n",
    "        accuracy = (num_correct / data_size[phase]) * 100\n",
    "        tb.add_scalar(phase + \" loss\", running_loss, epoch)\n",
    "        tb.add_scalar(phase + \" acc\", accuracy, epoch)\n",
    "        \n",
    "        if phase == 'val' and accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            best_model_weights = copy.deepcopy(network.state_dict())\n",
    "        \n",
    "        print(\"Epoch:\", epoch, phase, \"loss:\", running_loss, \"Number correct:\", num_correct, \"Accuracy:\", accuracy, \"%\")\n",
    "\n",
    "trained_model = network.load_state_dict(best_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Confusion Matrix\n",
    "# Need a tensor of predictions and a tensor of true values\n",
    "\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        \n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat((all_preds, preds), dim=0)\n",
    "        \n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number Correct: 50296\n",
      "Accuracy: 83.82666666666667\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # We do not need gradient tracking when making predicitons\n",
    "    prediction_loader= torch.utils.data.DataLoader(train_set, batch_size=100)\n",
    "    train_preds = get_all_preds(network, prediction_loader)\n",
    "    \n",
    "preds_correct = train_preds.argmax(dim=1).eq(train_set.targets).sum().item()\n",
    "\n",
    "print('Total Number Correct:', preds_correct)\n",
    "print('Accuracy:', preds_correct / data_size['train'] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = torch.zeros(10,10, dtype=torch.int32)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5178,   47,  120,  272,   18,   10,  216,    0,  139,    0],\n",
      "        [  27, 5748,   16,  151,    2,    1,   35,    0,   20,    0],\n",
      "        [  48,    0, 4704,   40,  756,    2,  387,    0,   63,    0],\n",
      "        [ 180,   86,   42, 5267,  228,    1,  135,    1,   60,    0],\n",
      "        [   7,    7,  924,  324, 4132,    2,  547,    0,   57,    0],\n",
      "        [   0,    0,    0,    1,    0, 5665,   15,  242,   15,   62],\n",
      "        [1590,   13,  837,  271,  533,    4, 2532,    0,  220,    0],\n",
      "        [   0,    0,    0,    0,    0,  113,    0, 5743,    3,  141],\n",
      "        [   7,    1,   57,   28,   24,   41,   84,   14, 5742,    2],\n",
      "        [   0,    0,    1,    2,    0,   81,    5,  315,   11, 5585]],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "stacked = torch.stack(\n",
    "    (train_set.targets,\n",
    "    train_preds.argmax(dim=1)),\n",
    "    dim=1)\n",
    "\n",
    "for p in stacked:\n",
    "    true_labels, predicted_labels = p.tolist()\n",
    "    confusion_matrix[true_labels, predicted_labels] = confusion_matrix[true_labels, predicted_labels] + 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
